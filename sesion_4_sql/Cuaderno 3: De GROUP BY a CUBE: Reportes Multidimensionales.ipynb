{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a7bd195-75cb-404b-980a-856992e339d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Cuaderno 3: Agregaciones para Business Intelligence**\n",
    "\n",
    "### **TEMA:** \"De GROUP BY a GROUP BY CUBE: Reportes Multidimensionales en una Sola Consulta\"\n",
    "\n",
    "**Objetivo:** Los participantes comprenderán las limitaciones de `UNION ALL` para crear reportes con subtotales y aprenderán a usar `ROLLUP`, `CUBE` y `GROUPING SETS` para generar agregaciones multidimensionales de forma eficiente y elegante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a135a82-f152-4bf9-8acb-050c1d1cc0ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Celda 1: Script para generar y configurar el conjunto de datos del taller\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DecimalType # Importante: Importar el tipo de dato necesario\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- SEMILLA PARA REPRODUCIBILIDAD ---\n",
    "# Garantiza que los datos generados sean siempre los mismos.\n",
    "SEED = 2025\n",
    "Faker.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Inicializar Faker\n",
    "fake = Faker('es_ES')\n",
    "\n",
    "# --- FUNCIONES DE GENERACIÓN DE DATOS ---\n",
    "def generar_usuarios(n=1000):\n",
    "    \"\"\"Genera una lista de diccionarios de usuarios.\"\"\"\n",
    "    return [{'id_usuario': 1000 + i, 'nombre': fake.name(), 'email': fake.email(), 'fecha_registro': fake.date_time_between(start_date='-2y'), 'ciudad': fake.city()} for i in range(n)]\n",
    "\n",
    "def generar_productos(n=500):\n",
    "    \"\"\"Genera una lista de productos.\"\"\"\n",
    "    categorias = ['Electrónica', 'Hogar', 'Ropa', 'Libros', 'Deportes', 'Juguetes', 'Alimentos']\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        data.append({\n",
    "            'id_producto': 2000 + i,\n",
    "            'nombre_producto': fake.word().capitalize() + \" \" + fake.word(),\n",
    "            'categoria': random.choice(categorias),\n",
    "            'precio_unitario': round(random.uniform(5.0, 350.0), 2)\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def generar_pedidos(usuarios, productos, n=10000):\n",
    "    \"\"\"Genera una lista de pedidos, vinculando usuarios y productos.\"\"\"\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        usuario = random.choice(usuarios)\n",
    "        producto = random.choice(productos)\n",
    "        cantidad = random.randint(1, 5)\n",
    "        data.append({\n",
    "            'id_pedido': 3000 + i,\n",
    "            'id_usuario': usuario['id_usuario'],\n",
    "            'id_producto': producto['id_producto'],\n",
    "            'cantidad': cantidad,\n",
    "            'monto': round(cantidad * producto['precio_unitario'], 2),\n",
    "            'fecha_pedido': fake.date_time_between(start_date=usuario['fecha_registro'])\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# --- CREACIÓN DE DATAFRAMES ---\n",
    "print(\"Generando datos simulados...\")\n",
    "usuarios_data = generar_usuarios()\n",
    "productos_data = generar_productos()\n",
    "pedidos_data = generar_pedidos(usuarios_data, productos_data)\n",
    "\n",
    "usuarios_df = spark.createDataFrame(usuarios_data)\n",
    "productos_df = spark.createDataFrame(productos_data)\n",
    "pedidos_df = spark.createDataFrame(pedidos_data)\n",
    "\n",
    "# --- CREACIÓN DE BASE DE DATOS Y TABLAS SILVER ---\n",
    "db_name = \"curso_arquitecturas\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "spark.sql(f\"USE {db_name}\")\n",
    "\n",
    "print(f\"Usando la base de datos: '{db_name}'\")\n",
    "\n",
    "# Guardar usuarios\n",
    "usuarios_df.selectExpr(\"id_usuario\", \"nombre as nombre_usuario\", \"email\", \"fecha_registro\", \"ciudad\") \\\n",
    "    .write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"usuarios_silver\")\n",
    "\n",
    "# ==================== LA CORRECCIÓN ESTÁ AQUÍ ====================\n",
    "# 1. Definimos explícitamente el tipo de dato para 'precio_unitario' antes de escribir.\n",
    "productos_df_casteado = productos_df.withColumn(\"precio_unitario\", productos_df[\"precio_unitario\"].cast(DecimalType(10, 2)))\n",
    "\n",
    "# 2. Escribimos el DataFrame corregido, permitiendo la sobreescritura del esquema para robustez.\n",
    "productos_df_casteado.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(\"productos_silver\")\n",
    "# =================================================================\n",
    "\n",
    "# Convertimos el DataFrame de pedidos a una tabla SQL temporal para poder usar funciones SQL\n",
    "pedidos_df.createOrReplaceTempView(\"pedidos_temp\")\n",
    "\n",
    "# Guardar pedidos con el esquema bien definido usando SQL\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE pedidos_silver AS\n",
    "SELECT \n",
    "  id_pedido, \n",
    "  id_usuario, \n",
    "  id_producto, \n",
    "  cantidad, \n",
    "  CAST(monto AS DECIMAL(18, 2)) AS monto_total, \n",
    "  fecha_pedido AS ts_pedido,\n",
    "  TO_DATE(fecha_pedido) as id_fecha \n",
    "FROM pedidos_temp\n",
    "\"\"\")\n",
    "\n",
    "# --- CREACIÓN DE DIM_FECHA ---\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE dim_fecha (\n",
    "  id_fecha DATE NOT NULL, anio INT, mes INT, dia INT, trimestre INT,\n",
    "  nombre_mes STRING, nombre_dia_semana STRING, tipo_dia STRING\n",
    ");\n",
    "\"\"\")\n",
    "spark.sql(\"\"\"\n",
    "INSERT INTO dim_fecha\n",
    "SELECT\n",
    "  fecha AS id_fecha, YEAR(fecha) AS anio, MONTH(fecha) AS mes, DAY(fecha) AS dia,\n",
    "  QUARTER(fecha) AS trimestre, DATE_FORMAT(fecha, 'MMMM') AS nombre_mes,\n",
    "  DATE_FORMAT(fecha, 'EEEE') AS nombre_dia_semana,\n",
    "  CASE WHEN DAYOFWEEK(fecha) IN (1, 7) THEN 'Fin de Semana' ELSE 'Día de Semana' END AS tipo_dia\n",
    "FROM (SELECT EXPLODE(SEQUENCE(TO_DATE('2022-01-01'), TO_DATE('2026-12-31'), INTERVAL 1 DAY)) AS fecha);\n",
    "\"\"\")\n",
    "\n",
    "print(\"Tablas Silver y dim_fecha creadas/actualizadas exitosamente.\")\n",
    "print(\"\\n¡Entorno listo para el Módulo 2!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1582349-708b-4faa-a1e1-4d61063d586a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Contexto:** El equipo de Business Intelligence necesita un único reporte que resuma el total de ventas (`monto_total`) con múltiples niveles de granularidad para un análisis multidimensional:\n",
    "\n",
    "1.  El detalle de ventas por **Categoría y Año** combinados.\n",
    "2.  Un **Subtotal** consolidado para cada **Categoría** (sumando todos los años).\n",
    "3.  Un **Subtotal** consolidado para cada **Año** (sumando todas las categorías).\n",
    "4.  Un **Gran Total** de todas las ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d422e08b-181d-4d44-9ed2-fa2827cd5102",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Análisis:** La primera aproximación, y la más común para quienes no conocen las mejoras de `GROUP BY`, es calcular cada nivel de agregación por separado y luego juntar los resultados con `UNION ALL`.\n",
    "\n",
    "Este enfoque es un **anti-patrón** por dos razones principales:\n",
    "* **Rendimiento Pobre:** Obliga al motor de Spark a escanear la tabla de hechos (`pedidos_silver`) **cuatro veces**, una por cada `SELECT`. En tablas con miles de millones de filas, esto es computacionalmente inaceptable.\n",
    "* **Mantenimiento Complejo:** El código es repetitivo y difícil de mantener. Si se necesita añadir un nuevo filtro (ej. `WHERE ciudad = 'Bogotá D.C.'`), hay que recordarlo y aplicarlo en cuatro lugares distintos, lo que es propenso a errores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8f27198a-09b4-4054-89f5-8641f7e26de5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- \"Mala\" Solución: Unir 4 consultas separadas\n",
    "-- Consulta 1: Detalle por Categoría y Año\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  d.anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY pr.categoria, d.anio\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Consulta 2: Subtotal por Categoría\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  NULL AS anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY pr.categoria\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Consulta 3: Subtotal por Año\n",
    "SELECT\n",
    "  NULL AS categoria,\n",
    "  d.anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY d.anio\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "-- Consulta 4: Gran Total\n",
    "SELECT\n",
    "  NULL AS categoria,\n",
    "  NULL AS anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ae4b092-0c5e-4ac0-b6df-af9840dda5cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Análisis:** `ROLLUP` es una extensión de `GROUP BY` que calcula subtotales de manera jerárquica. Es perfecto para crear reportes que necesitan un \"desglose\" (drill-down) desde un nivel general a uno más detallado, siguiendo el orden de las columnas especificadas.\n",
    "\n",
    "`ROLLUP(A, B)` calculará las agregaciones para:\n",
    "1.  `(A, B)`\n",
    "2.  `(A)`\n",
    "3.  `()` (El gran total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c636985-4158-4e0c-bac4-41efa2096e16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Con ROLLUP, obtenemos 3 de los 4 niveles que necesitamos\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  d.anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY ROLLUP(pr.categoria, d.anio)\n",
    "ORDER BY pr.categoria, d.anio;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25a7364b-d369-47ac-a14d-727794bb3143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**`GROUP BY ROLLUP(categoria, anio)`** le dice a la base de datos:\n",
    "\n",
    "1.  Primero, agrupa por la combinación de `(categoria, anio)`.\n",
    "2.  Luego, \"sube un nivel\" y agrupa solo por `(categoria)`, creando un subtotal para cada una.\n",
    "3.  Finalmente, \"sube al nivel más alto\" y calcula el gran total para `()`.\n",
    "\n",
    "Las filas de subtotal se identifican porque la columna que se está agregando en ese nivel aparece como `NULL`.\n",
    "\n",
    "**Limitación:** `ROLLUP` es jerárquico. `ROLLUP(categoria, anio)` **no** nos da el subtotal solo por `anio`. Para eso, necesitamos una herramienta más poderosa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5944c06-b087-4855-8817-13e27ee7ea09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Análisis:** `CUBE` es la herramienta definitiva para análisis multidimensional. A diferencia de `ROLLUP`, `CUBE` genera subtotales para **todas las combinaciones posibles** de las columnas especificadas.\n",
    "\n",
    "`CUBE(A, B)` calculará las agregaciones para:\n",
    "1.  `(A, B)`\n",
    "2.  `(A)`\n",
    "3.  `(B)`\n",
    "4.  `()` (El gran total)\n",
    "\n",
    "Esto resuelve nuestro problema de negocio de forma completa y eficiente, escaneando los datos **una sola vez**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20feaf1e-6885-4ff0-934d-b5a680d5bfd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Con CUBE, obtenemos los 4 niveles requeridos en una sola consulta\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  d.anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY CUBE(pr.categoria, d.anio)\n",
    "ORDER BY pr.categoria, d.anio;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e0bacc4-5d3c-4efb-a038-a07bdb6a3ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Análisis:** `CUBE` crea un \"cubo\" de datos con todas las posibles vistas de agregación. Pero, ¿cómo distinguimos una fila de subtotal (`NULL`) de una fila donde el valor original era realmente `NULL`?\n",
    "\n",
    "La respuesta es la función `grouping_id()`. Esta función devuelve un entero que actúa como un mapa de bits, indicando qué columnas están siendo agregadas en esa fila.\n",
    "\n",
    "Para `CUBE(categoria, anio)`:\n",
    "- `grouping_id() = 0`: Agregación por `(categoria, anio)` (ninguna es `NULL` de subtotal).\n",
    "- `grouping_id() = 1`: Agregación por `(categoria)` (`anio` es `NULL` de subtotal).\n",
    "- `grouping_id() = 2`: Agregación por `(anio)` (`categoria` es `NULL` de subtotal).\n",
    "- `grouping_id() = 3`: Gran total (`categoria` y `anio` son `NULL` de subtotal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d70303f-10da-459b-8609-c2b3fbae3876",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Usando grouping_id() para crear una columna descriptiva\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  d.anio,\n",
    "  grouping_id() AS nivel_agregacion,\n",
    "  CASE grouping_id()\n",
    "    WHEN 0 THEN 'Detalle por Categoría y Año'\n",
    "    WHEN 1 THEN 'Subtotal por Categoría'\n",
    "    WHEN 2 THEN 'Subtotal por Año'\n",
    "    WHEN 3 THEN 'Gran Total'\n",
    "  END AS descripcion_nivel,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY CUBE(pr.categoria, d.anio)\n",
    "ORDER BY pr.categoria, d.anio;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90056d20-e3c8-43a2-9df6-2a2bfd2b424d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Análisis:** ¿Qué pasa si no necesitas *todas* las combinaciones de `CUBE`? `GROUPING SETS` te da el control quirúrgico para especificar exactamente qué combinaciones de agregación quieres, evitando cálculos innecesarios.\n",
    "\n",
    "`ROLLUP` y `CUBE` son, en realidad, atajos para `GROUPING SETS` más complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fbeb29-5741-4698-b0a9-f132d38e9e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Requerimiento: Solo necesitamos el detalle (categoria, anio) y el subtotal por (anio)\n",
    "SELECT\n",
    "  pr.categoria,\n",
    "  d.anio,\n",
    "  SUM(p.monto_total) AS total_ventas\n",
    "FROM pedidos_silver p\n",
    "JOIN productos_silver pr ON p.id_producto = pr.id_producto\n",
    "JOIN dim_fecha d ON p.id_fecha = d.id_fecha\n",
    "GROUP BY GROUPING SETS (\n",
    "  (pr.categoria, d.anio),  -- Set 1: El nivel de detalle\n",
    "  (d.anio)                 -- Set 2: El subtotal por año\n",
    ")\n",
    "ORDER BY\n",
    "  pr.categoria, d.anio;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2bb27eb3-31bb-4d3e-8a58-bb31f3e35e4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Tu Tarea:** El equipo de marketing quiere analizar la adquisición de nuevos usuarios. Necesitan un único reporte que muestre, usando la tabla `usuarios_silver` y la `dim_fecha`:\n",
    "\n",
    "**Requerimiento:** Generar el conteo de nuevos usuarios (`COUNT(id_usuario)`) para los siguientes niveles:\n",
    "1.  El número de usuarios registrados por **año**.\n",
    "2.  El número de usuarios registrados por **ciudad**.\n",
    "3.  El número de usuarios registrados por **año y ciudad**.\n",
    "4.  El **total general** de usuarios registrados.\n",
    "\n",
    "**Pregunta:** ¿Qué operador (`ROLLUP` o `CUBE`) es el más adecuado para generar todos estos niveles en una sola consulta? Escribe la consulta completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f79e65dd-4fac-471c-ae4e-c5a93ad2fc92",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Escribe tu solución para el ejercicio aquí..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e9517ea-6193-41ca-b1aa-7e3b9063d1fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---\n",
    "**Ideas Clave:**\n",
    "* **Anti-Patrón:** Usar múltiples `UNION ALL` para crear reportes con subtotales es ineficiente y difícil de mantener.\n",
    "* **`ROLLUP`:** Genera subtotales **jerárquicos**. Ideal para desgloses (drill-down).\n",
    "* **`CUBE`:** Genera subtotales para **todas las combinaciones**. Perfecto para exploración multidimensional.\n",
    "* **`GROUPING SETS`:** Ofrece **control total** para especificar solo las agregaciones que necesitas.\n",
    "* **`grouping_id()`:** Es la función esencial para identificar y etiquetar los niveles de subtotal en tus resultados, haciéndolos legibles para humanos y herramientas de BI.\n",
    "\n",
    "**Lección Principal:** Abandona el `UNION ALL` para subtotales y adopta las mejoras de `GROUP BY`. Escribirás código más limpio, más rápido y más fácil de mantener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c1015d9-ba6e-4ffd-b407-271908a56fca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Solución: CUBE es la herramienta correcta porque necesitamos todas las combinaciones posibles.\n",
    "SELECT\n",
    "  d.anio AS anio_registro,\n",
    "  u.ciudad,\n",
    "  CASE grouping_id()\n",
    "      WHEN 0 THEN 'Detalle por Año y Ciudad'\n",
    "      WHEN 1 THEN 'Subtotal por Año'\n",
    "      WHEN 2 THEN 'Subtotal por Ciudad'\n",
    "      WHEN 3 THEN 'Gran Total'\n",
    "  END AS descripcion_nivel,\n",
    "  COUNT(u.id_usuario) AS total_usuarios\n",
    "FROM\n",
    "  usuarios_silver u\n",
    "JOIN \n",
    "  dim_fecha d ON TO_DATE(u.fecha_registro) = d.id_fecha\n",
    "GROUP BY CUBE(d.anio, u.ciudad)\n",
    "ORDER BY\n",
    "  anio_registro, ciudad;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "faker"
    ],
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7887307683622323,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Cuaderno 3: De GROUP BY a CUBE: Reportes Multidimensionales",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
